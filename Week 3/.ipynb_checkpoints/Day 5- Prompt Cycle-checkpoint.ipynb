{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9395ee5a-4795-46de-88f0-f986eb6200d3",
   "metadata": {},
   "source": [
    "# DAY 5: The Beating Heart of Intelligent Agents -- Understanding the Prompt-to-Response Cycle\n",
    "## Lab 2: Prompt–Response Cycles with LLMs\n",
    "### Goal: Understand and experiment with how an LLM processes prompts, maintains context, and produces responses across multiple turns.\n",
    "- Estimated Time: 75–90 minutes\n",
    "- Deliverable: A notebook/script showing single-turn, multi-turn, and context-reset prompt–response cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d62692-f919-4179-a087-defbcc876889",
   "metadata": {},
   "source": [
    "### Step-by-Step Instructions\n",
    "### 1. Setup (5 min)\n",
    "- Make sure you’re in your agentic_env venv with the OpenAI SDK installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5743f12c-c4b2-436d-a74a-69454bf827b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./agentic_env/lib/python3.13/site-packages (1.109.1)\n",
      "Requirement already satisfied: python-dotenv in ./agentic_env/lib/python3.13/site-packages (1.1.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./agentic_env/lib/python3.13/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./agentic_env/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./agentic_env/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./agentic_env/lib/python3.13/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./agentic_env/lib/python3.13/site-packages (from openai) (2.12.0)\n",
      "Requirement already satisfied: sniffio in ./agentic_env/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./agentic_env/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./agentic_env/lib/python3.13/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./agentic_env/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./agentic_env/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in ./agentic_env/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./agentic_env/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./agentic_env/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in ./agentic_env/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./agentic_env/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ec1e31-6fb6-47a4-91b0-6cadc82b8a0c",
   "metadata": {},
   "source": [
    "### 2. Define a Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff4e9241-b975-4287-add3-2240747cce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cycle_lab.py:\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    " \n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    " \n",
    "def chat_cycle(messages):\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "# This will let you reuse messages for multi-turn conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65c710f-8cde-4424-aec8-18922a977c39",
   "metadata": {},
   "source": [
    "### 3. Single-Turn Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44306086-4160-4186-bdd5-13265e0f1429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic AI refers to artificial intelligence systems that possess the ability to act autonomously, make decisions based on their environment, and pursue goals without direct human intervention.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Explain Agentic AI in one sentence.\"}]\n",
    "print(chat_cycle(messages))\n",
    "\n",
    "# Run it twice — observe variability.\n",
    "# Add precision: “Explain Agentic AI in exactly 10 words.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed0b6e7-b72e-4130-b0e0-1b36f4a44747",
   "metadata": {},
   "source": [
    "### Step 4. Multi-Turn Conversations (15 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aae99d2e-27ff-4d7e-911e-080f46ce2961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: An AI agent is a system that can perceive its environment, make decisions, and take actions to achieve specific objectives. These agents use various forms of artificial intelligence, such as machine learning, heuristic algorithms, or rule-based systems, to interpret data and respond in a manner that appears intelligent. \n",
      "\n",
      "AI agents can be classified into several types, including:\n",
      "\n",
      "1. **Reactive Agents**: These operate only based on the current state of the environment without considering the past. They respond to stimuli in a straightforward manner.\n",
      "\n",
      "2. **Deliberative Agents**: These have some level of memory and can plan ahead by considering their goals, past actions, and future consequences.\n",
      "\n",
      "3. **Learning Agents**: These can improve their performance over time through experience, adapting their behavior based on feedback from their environment.\n",
      "\n",
      "4. **Autonomous Agents**: These operate without human intervention, making their own decisions based on their programming and the data they receive.\n",
      "\n",
      "AI agents can be found in many applications, such as virtual personal assistants (like Siri or Alexa), autonomous vehicles, recommendation systems, video game characters, and customer service chatbots. Their design and complexity can vary significantly depending on the tasks they are intended to perform.\n",
      "AI: Certainly! One prominent example of an AI agent in healthcare is a **clinical decision support system (CDSS)**. These systems help healthcare professionals make informed decisions about patient care based on large amounts of data.\n",
      "\n",
      "### Example: Clinical Decision Support System (CDSS)\n",
      "\n",
      "1. **Functionality**: A CDSS uses AI algorithms to analyze patient data (such as medical history, symptoms, lab results, and medication) to provide evidence-based recommendations. For instance, it might suggest potential diagnoses, recommend treatment options, or flag potential drug interactions.\n",
      "\n",
      "2. **Data Sources**: The system can pull data from electronic health records (EHR), medical literature, and clinical guidelines to create a comprehensive view of the patient's health status.\n",
      "\n",
      "3. **Use Case**: Imagine a physician evaluating a patient with various symptoms. The CDSS analyzes the patient's data and highlights possible conditions based on similar cases from its database. It might indicate that the symptoms are consistent with a specific disease, recommend diagnostic tests, or suggest treatment protocols.\n",
      "\n",
      "4. **Benefits**:\n",
      "   - **Improved Accuracy**: By providing evidence-based suggestions, the CDSS can help reduce diagnostic errors.\n",
      "   - **Efficiency**: It saves time for healthcare providers by quickly synthesizing vast amounts of medical knowledge.\n",
      "   - **Personalized Care**: The system can tailor recommendations based on individual patient characteristics.\n",
      "\n",
      "### Example in Action:\n",
      "A practical example of AI in healthcare is IBM Watson for Oncology, which analyzes data from medical literature and clinical trials to assist oncologists in treatment decisions for cancer patients. It evaluates the specifics of individual cases and suggests personalized treatment options based on the most current research and guidelines.\n",
      "\n",
      "These applications illustrate how AI agents can enhance decision-making in healthcare, leading to improved patient outcomes and more efficient care processes.\n"
     ]
    }
   ],
   "source": [
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a friendly teaching assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is an AI agent?\"},\n",
    "]\n",
    "reply1 = chat_cycle(conversation)\n",
    "print(\"AI:\", reply1)\n",
    " \n",
    "# Add another turn\n",
    "conversation.append({\"role\": \"assistant\", \"content\": reply1})\n",
    "conversation.append({\"role\": \"user\", \"content\": \"Can you give me an example in healthcare?\"})\n",
    "reply2 = chat_cycle(conversation)\n",
    "print(\"AI:\", reply2)\n",
    "# Notice how the assistant remembers context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de82fab-297e-4a50-a393-14fb01c7915c",
   "metadata": {},
   "source": [
    "### Step 5 Context Window Experiment (15 min)\n",
    "- Keep adding user–assistant turns until responses get vague or inconsistent.\n",
    "- Try copying and pasting a long article as input, then continue the dialogue.\n",
    "- Observe where the LLM “forgets” early context → this demonstrates context window limits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dd3855-4083-4d83-861e-6160b12a9b24",
   "metadata": {},
   "source": [
    "### Step 6. Controlled Output Cycles (15 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1323bac4-8ba0-4a17-94dc-6f5d1d679642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Agentic_AITools\": [\n",
      "    \"Reinforcement Learning Frameworks\",\n",
      "    \"Natural Language Processing Libraries\",\n",
      "    \"Computer Vision Software\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Ask for structured responses:\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a JSON-only assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"List 3 tools used in Agentic AI.\"}\n",
    "]\n",
    "print(chat_cycle(messages))\n",
    "\n",
    "#Test with YAML, bullet lists, tables.\n",
    "# Compare free-form vs constrained formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8e1691-b091-4fca-af1c-0b49bd931680",
   "metadata": {},
   "source": [
    "### 7. Mini Project: Q&A Agent Simulation (15–20 min)\n",
    "- Build a loop that takes user input repeatedly and maintains context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384c8e1-1d9d-4a27-a7d0-00ba92663f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is RAG?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: RAG can refer to different concepts depending on the context. Here are a few common meanings:\n",
      "\n",
      "1. **RAG (Red Amber Green) Reporting**: In project management and performance tracking, RAG is a way to indicate the status of a project using a color-coded system. \"Red\" usually signifies serious issues or problems, \"Amber\" indicates caution or potential problems, and \"Green\" means everything is on track.\n",
      "\n",
      "2. **RAG (Retrieval-Augmented Generation)**: In natural language processing and artificial intelligence, RAG refers to a model architecture that combines retrieval and generation. It uses a retrieval mechanism to find relevant information from a knowledge base and then generates a coherent answer or response based on that information. This approach enhances the model's ability to produce accurate and contextually relevant outputs.\n",
      "\n",
      "3. **Rag (Fabric)**: In a textile context, a rag is a piece of cloth or fabric that is often discarded or used for cleaning or other practical purposes.\n",
      "\n",
      "4. **RAG Week**: In some universities, particularly in the UK and Ireland, RAG Week refers to a charity fundraising event organized by students where various activities are held to raise money for charitable causes.\n",
      "\n",
      "If you meant something else by \"RAG,\" please provide more context!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  why is RAG important?, How does memory help an agent?, “Give an analogy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: RAG (Retrieval-Augmented Generation) is important for several reasons, especially in the context of AI and natural language processing:\n",
      "\n",
      "### Importance of RAG\n",
      "\n",
      "1. **Accuracy and Relevance**: RAG models can provide more accurate and contextually relevant responses by retrieving specific information from a knowledge base. This helps in situations where static models may lack the necessary detail.\n",
      "\n",
      "2. **Combining Strengths**: It effectively combines the strengths of retrieval-based methods (which can access vast amounts of data) with generative methods (which can create coherent narrative text). This hybrid approach can improve overall performance.\n",
      "\n",
      "3. **Knowledge Update**: As new information becomes available, the retrieval mechanism can access updated data, allowing the model to stay relevant without needing complete retraining.\n",
      "\n",
      "4. **Handling Complexity**: In complex queries or when dealing with specialized topics, RAG models can fetch suitable content from a vast corpus, which enhances understanding and response quality.\n",
      "\n",
      "### Memory's Role in an Agent\n",
      "\n",
      "Memory in an AI agent allows it to retain and access past experiences, interactions, and knowledge, which plays a crucial role in improving the agent's performance:\n",
      "\n",
      "1. **Contextual Awareness**: Memory helps the agent maintain context over conversations or interactions, allowing for more coherent and relevant responses.\n",
      "\n",
      "2. **Learning from Experience**: By storing past interactions, the agent can learn from them, adapt its strategies, and improve over time based on user preferences or feedback.\n",
      "\n",
      "3. **Personalization**: Memory enables the agent to remember user-specific information, helping it tailor responses to individual needs and making interactions more user-friendly.\n",
      "\n",
      "### Analogy\n",
      "\n",
      "Think of RAG and memory in AI like a librarian and a book reader:\n",
      "\n",
      "- **RAG**: Imagine a book reader who, when faced with a question, first consults a librarian (the retrieval mechanism) to find the most relevant books (information) on the topic before crafting a narrative or summary of the information. This ensures that the reader's output is accurate and informed by the best available resources.\n",
      "\n",
      "- **Memory**: Now, if the reader has a good memory, they recall details from past readings when responding to new questions. This allows them to blend their own knowledge with the new information the librarian provided, creating a richer, more informed response based on both past experiences and current research.\n",
      "\n",
      "In this analogy, the librarian signifies the RAG mechanism, while the reader's memory illustrates how an agent's memory enhances its responses.\n"
     ]
    }
   ],
   "source": [
    "conversation = [{\"role\": \"system\", \"content\": \"You are an educational AI tutor.\"}]\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"exit\",\"quit\"]: break\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "    reply = chat_cycle(conversation)\n",
    "    print(\"AI:\", reply)\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": reply})\n",
    "# Ask a sequence of related questions (“What is RAG?”, “How does memory help an agent?”, “Give an analogy.”).\n",
    "# Notice how the model builds continuity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d52388d-97be-42c9-896c-6f9cf918cb8f",
   "metadata": {},
   "source": [
    "- By the end of this lab, you’ll see how LLMs sustain dialogue across turns, manage context, and produce structured outputs—a crucial foundation for agents that think, plan, and act iteratively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
